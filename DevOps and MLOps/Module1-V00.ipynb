{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Terms\n",
    "\n",
    "Microservice - Encapsulated, reusable logic that is deployed into production environments.\n",
    "\n",
    "Continuous Integration (CI) - The practice of frequently merging code changes into a shared repository and automatically building and testing changes to catch issues early.\n",
    "\n",
    "Continuous Delivery - A development practice where incremental software changes can be reliably released at any time through automated deployments.\n",
    "\n",
    "End-to-End MLOps - Fully automating the machine learning lifecycle from model development through deployment and hosting via platforms like Hugging Face Spaces.\n",
    "\n",
    "AWS App Runner - A fully managed service for deploying containerized web services and APIs.\n",
    "\n",
    "Flask - A popular, lightweight Python web application framework.\n",
    "\n",
    "Makefile - A file containing a set of directives used to automate building and managing a project.\n",
    "\n",
    "Requirements File - A text file containing a list of Python package dependencies used by an application.\n",
    "## Top 3 Key Points:\n",
    "\n",
    "MLOps inherits from DevOps and brings automation to ML\n",
    "\n",
    "A lightweight or heavy MLOps approach depends on needs\n",
    "\n",
    "Must have DevOps first, then data ops, MLOps platform, and business alignment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflection Question- Short Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**1. How is MLOps different from traditional software engineering?**\n",
    "MLOps focuses on managing the full ML lifecycle—data, models, and deployment—whereas traditional software engineering mainly manages code and application logic.\n",
    "\n",
    "**2. When would you choose a lightweight vs heavy MLOps system?**\n",
    "Lightweight for small projects or quick experiments; heavy for large, complex systems that need scalability, monitoring, and governance.\n",
    "\n",
    "**3. What cultural changes are needed to adopt MLOps practices?**\n",
    "Teams must embrace collaboration between data scientists, engineers, and operations, and adopt continuous improvement and automation mindsets.\n",
    "\n",
    "**4. How could data poisoning threats impact an organization?**\n",
    "They can corrupt training data, leading to biased or malicious models that harm decision-making and trust.\n",
    "\n",
    "**5. Why is business alignment important for MLOps success?**\n",
    "Without business alignment, ML efforts risk producing models that don’t deliver real value or solve the right problems.\n",
    "\n",
    "**6. What data storage approach best meets your model training needs?**\n",
    "Choose based on data type and scale—structured data may suit relational databases, while large unstructured data needs object storage.\n",
    "\n",
    "**7. Which maturity level best describes your team's current MLOps state?**\n",
    "Depends on your practices—manual workflows = early stage, automated pipelines with monitoring = advanced.\n",
    "\n",
    "**8. How could a centralized feature store help your model development process?**\n",
    "It standardizes features, reduces duplication, and ensures consistency between training and serving environments.\n",
    "\n",
    "**9. What cultural changes are needed to implement CI/CD pipelines?**\n",
    "A shift toward automation, rapid iteration, and shared responsibility for code quality and deployment.\n",
    "\n",
    "**10. Which MLOps platform provider is best suited to your applications?**\n",
    "The one that matches your needs—AWS for scalability, GCP for AI tools, Azure for enterprise integration, or open-source for flexibility.\n",
    "\n",
    "**11. What types of logic would work well packaged as a microservice?**\n",
    "Reusable, independent tasks like prediction APIs, data validation, or preprocessing pipelines.\n",
    "\n",
    "**12. How could you improve the CI/CD pipeline example?**\n",
    "Add automated tests, monitoring, rollback strategies, and security checks to make it more robust.\n",
    "\n",
    "**13. What other pre-trained models could you deploy besides Hugging Face?**\n",
    "Models from TensorFlow Hub, PyTorch Hub, or OpenAI APIs depending on your task.\n",
    "\n",
    "**14. How else could App Runner or Flask apps be triggered besides HTTP?**\n",
    "Via event-driven triggers such as message queues, cron jobs, or cloud functions.\n",
    "\n",
    "**15. Why is having a requirements.txt file important?**\n",
    "It ensures consistent dependencies across environments, making projects reproducible and easier to share.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge Questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **Challenge 1: Diagram your own organizational MLOps landscape architecture**\n",
    "\n",
    "\n",
    "                ┌───────────────────────────────┐\n",
    "                │   Business Use Cases / Apps   │\n",
    "                └───────────────┬───────────────┘\n",
    "                                │\n",
    "                 ┌──────────────▼───────────────┐\n",
    "                 │   Data Sources (DBs, APIs,   │\n",
    "                 │  Data Lakes, Streaming, etc.)│\n",
    "                 └───────────────┬──────────────┘\n",
    "                                 │\n",
    "             ┌───────────────────▼───────────────────┐\n",
    "             │        Data Ingestion & Storage        │\n",
    "             │ (ETL, Data Warehouse, Feature Store)   │\n",
    "             └───────────────────┬───────────────────┘\n",
    "                                 │\n",
    "                 ┌───────────────▼───────────────┐\n",
    "                 │    Model Development / Lab    │\n",
    "                 │ (Notebooks, Experiment Mgmt,  │\n",
    "                 │   Versioning, CI/CD)          │\n",
    "                 └───────────────┬───────────────┘\n",
    "                                 │\n",
    "                 ┌───────────────▼───────────────┐\n",
    "                 │     Model Training & Eval     │\n",
    "                 │  (Pipelines, AutoML, GPUs)    │\n",
    "                 └───────────────┬───────────────┘\n",
    "                                 │\n",
    "                 ┌───────────────▼───────────────┐\n",
    "                 │   Deployment & Serving Layer  │\n",
    "                 │ (Microservices, APIs, Batch,  │\n",
    "                 │   Real-time Inference)        │\n",
    "                 └───────────────┬───────────────┘\n",
    "                                 │\n",
    "                 ┌───────────────▼───────────────┐\n",
    "                 │ Monitoring & Feedback Loops   │\n",
    "                 │ (Drift Detection, Logging,    │\n",
    "                 │   Retraining Triggers)        │\n",
    "                 └───────────────────────────────┘\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Challenge 2: Interview teams to create your own maturity model assessment**\n",
    "\n",
    "This one is less about coding and more about **process + framework**.\n",
    "The idea: you “interview” different teams (data science, engineering, DevOps, product) and assess **where they stand** on MLOps practices.\n",
    "\n",
    "Here’s a **simple maturity model (4 levels)** you can use in those interviews:\n",
    "\n",
    "1. **Level 1 – Initial / Ad hoc**\n",
    "\n",
    "   * Models built in notebooks, manual deployment.\n",
    "   * No versioning, little collaboration.\n",
    "\n",
    "2. **Level 2 – Repeatable / Basic Automation**\n",
    "\n",
    "   * Code + data versioned (Git, DVC).\n",
    "   * Basic CI/CD pipeline for ML models.\n",
    "   * Manual monitoring.\n",
    "\n",
    "3. **Level 3 – Defined / Standardized**\n",
    "\n",
    "   * Central feature store.\n",
    "   * Automated training + deployment pipelines.\n",
    "   * Continuous monitoring for drift/performance.\n",
    "\n",
    "4. **Level 4 – Optimized / Scalable**\n",
    "\n",
    "   * End-to-end automation (data → training → deploy → retrain).\n",
    "   * Governance, explainability, compliance.\n",
    "   * Business-aligned metrics drive retraining.\n",
    "\n",
    "---\n",
    "\n",
    "💡 **How to “interview”:**\n",
    "\n",
    "* Ask **data scientists** → How do you track experiments?\n",
    "* Ask **DevOps** → How do you deploy ML models?\n",
    "* Ask **engineers** → How do you monitor and test ML code?\n",
    "* Ask **business team** → Are ML outputs tied to KPIs?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 3: Check out the ml-ops-ci-demo folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 4: Prototype a Feature Store \n",
    "Organize into feature groups (tables). Example:\n",
    "\n",
    "Customer Profile Features → static attributes\n",
    "\n",
    "customer_id (key)\n",
    "\n",
    "age\n",
    "\n",
    "gender\n",
    "\n",
    "signup_date\n",
    "\n",
    "Behavioral Features → usage patterns\n",
    "\n",
    "avg_session_length\n",
    "\n",
    "last_login_days\n",
    "\n",
    "clicks_past_week\n",
    "\n",
    "Transaction Features → spending history\n",
    "\n",
    "total_spent\n",
    "\n",
    "avg_monthly_spend\n",
    "\n",
    "purchase_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "source": [
    "CREATE TABLE customer_profile (\n",
    "    customer_id VARCHAR PRIMARY KEY,\n",
    "    age INT,\n",
    "    gender VARCHAR,\n",
    "    signup_date DATE\n",
    ");\n",
    "\n",
    "-- Behavioral Features\n",
    "\n",
    "CREATE TABLE customer_behavior (\n",
    "    customer_id VARCHAR PRIMARY KEY,\n",
    "    avg_session_length FLOAT,\n",
    "    last_login_days INT,\n",
    "    clicks_past_week INT\n",
    ");\n",
    "\n",
    "-- Transaction Features\n",
    "\n",
    "CREATE TABLE customer_transactions (\n",
    "    customer_id VARCHAR PRIMARY KEY,\n",
    "    total_spent FLOAT,\n",
    "    avg_monthly_spend FLOAT,\n",
    "    purchase_count INT\n",
    ");\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 5: Basic MLOps Pipeline (Data → Training → Deployment)\n",
    "## Check ml-ops-pipeline-demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Challenge 6: Diagram a lightweight MLOps workflow for a hobby project**.\n",
    "\n",
    "This one is **theory + diagram**, meant to show how a small-scale setup would look (for personal projects, prototypes, or class assignments).\n",
    "\n",
    "## 🚀 Lightweight MLOps Workflow (Hobby Project)\n",
    "\n",
    "```\n",
    "      ┌─────────────────────┐\n",
    "      │   Data Collection   │\n",
    "      │ (CSV files, APIs)   │\n",
    "      └─────────┬───────────┘\n",
    "                │\n",
    "      ┌─────────▼───────────┐\n",
    "      │   Data Prep & EDA   │\n",
    "      │ (Notebooks, Pandas) │\n",
    "      └─────────┬───────────┘\n",
    "                │\n",
    "      ┌─────────▼───────────┐\n",
    "      │   Training Script   │\n",
    "      │ (scikit-learn, etc.)│\n",
    "      └─────────┬───────────┘\n",
    "                │\n",
    "      ┌─────────▼───────────┐\n",
    "      │ Save Model Artifact │\n",
    "      │ (pickle, joblib)    │\n",
    "      └─────────┬───────────┘\n",
    "                │\n",
    "      ┌─────────▼───────────┐\n",
    "      │ Simple Deployment   │\n",
    "      │ (Flask API)         │\n",
    "      └─────────┬───────────┘\n",
    "                │\n",
    "      ┌─────────▼───────────┐\n",
    "      │   Manual Testing    │\n",
    "      │ (curl/Postman)      │\n",
    "      └─────────────────────┘\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 🔑 Key Notes for Hobby Workflow\n",
    "\n",
    "* **Data** → simple files (CSV, JSON, API dumps). No big data infra.\n",
    "* **Training** → run in notebooks or a single script.\n",
    "* **Model Storage** → save as `model.pkl` or `joblib` file.\n",
    "* **Deployment** → Flask or FastAPI, maybe Docker if needed.\n",
    "* **Testing** → manual (curl, Postman), not automated monitoring.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 7 : Set up a basic MLOPs pipeline using open source tools\n",
    "## Check same demo as above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 8 : Interview DevOps teams on lessons for MLOps adoption\n",
    "👉 Ask DevOps about automation, monitoring, deployment pain points. Summarize lessons like:\n",
    "\n",
    "Automate testing and deployment.\n",
    "\n",
    "Monitor for failures and drift.\n",
    "\n",
    "Build CI/CD culture around ML.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 9: Research real-world examples of data poisoning issues\n",
    "👉 Example answers:\n",
    "\n",
    "Microsoft’s Tay chatbot was poisoned by malicious inputs.\n",
    "\n",
    "Attackers can inject fake reviews into training data to bias recommendations.\n",
    "\n",
    "Poisoning can lead to reputational damage and faulty predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 10: Analyze costs/benefits of ML for a business case\n",
    "👉 Benefits: better predictions, automation, customer insights.\n",
    "👉 Costs: infrastructure, talent, ongoing monitoring.\n",
    "👉 Answer: Always balance ROI — don’t build ML unless benefits clearly outweigh costs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 11: Research other MLOps platforms to replace Hugging Face\n",
    "👉 Examples: MLflow, Kubeflow, TFX (TensorFlow Extended), SageMaker, Azure ML, Google Vertex AI. Each has different strengths in orchestration, experiment tracking, or deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🚀 Challenge 11: Containerize and Deploy the Flask Random Fruit Microservice\n",
    "\n",
    "## 📝 Summary: Flask Random Fruit Microservice - Check ml-ops-microservice-demo\n",
    "\n",
    "1. **Built a simple Flask app (`app.py`)** → returns a random fruit at `/fruit`.\n",
    "\n",
    "   * Purpose: Demonstrate a lightweight microservice.\n",
    "\n",
    "2. **Created `requirements.txt`** → listed dependencies (`flask`).\n",
    "\n",
    "   * Purpose: Ensure environment reproducibility.\n",
    "\n",
    "3. **Wrote a `Dockerfile`** → defined how to package the app into a container.\n",
    "\n",
    "   * Purpose: Make the service portable and consistent.\n",
    "\n",
    "4. **Built the Docker image** → `docker build -t flask-fruit .`.\n",
    "\n",
    "   * Purpose: Bundle code + dependencies into a single image.\n",
    "\n",
    "5. **Ran the container** → `docker run -p 5001:5000 flask-fruit`.\n",
    "\n",
    "   * Purpose: Deploy the app locally inside Docker.\n",
    "\n",
    "6. **Tested the endpoint** → `curl http://127.0.0.1:5001/fruit`.\n",
    "\n",
    "   * Purpose: Verify the containerized service works as expected.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
